{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T11:23:41.883361Z",
     "start_time": "2025-12-18T11:23:36.614922Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "import logging\n",
    "import warnings\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# ML & Preprocessing\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, accuracy_score,\n",
    "    f1_score, roc_auc_score, roc_curve, precision_recall_curve\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Note: Requires 'pip install imbalanced-learn shap'\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import shap\n",
    "from streamlit import header\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "class LogisticGuardian:\n",
    "    \"\"\"\n",
    "    Unified System for Training and Predicting Logistics Delays.\n",
    "    \"\"\"\n",
    "    def __init__(self, data_path: str = \"dataset_logistica_ml_10k.csv\"):\n",
    "        self.data_path = data_path\n",
    "        self.model_filename = \"models/logistic_guardian_v3_2.pkl\"\n",
    "        self.viz_dir = Path(\"visualizations\")\n",
    "        self.log_dir = Path(\"logs\")\n",
    "\n",
    "        # Setup folders\n",
    "        for folder in [self.viz_dir, self.log_dir, Path(\"models\")]:\n",
    "            folder.mkdir(exist_ok=True)\n",
    "\n",
    "        self._setup_logging()\n",
    "        self.pipeline = None\n",
    "\n",
    "        # Schema definition\n",
    "        self.numeric_features = [\n",
    "            \"distanza_km\", \"valore_merce_eur\", \"peso_kg\",\n",
    "            \"numero_transiti\", \"rischio_meteo\", \"rischio_doganale\"\n",
    "        ]\n",
    "        self.categorical_features = [\"modalit√†_trasporto\", \"fragile\", \"tracking_gps\"]\n",
    "        self.target = \"ritardo\"\n",
    "\n",
    "    def _setup_logging(self):\n",
    "        logging.basicConfig(\n",
    "            level=logging.INFO,\n",
    "            format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "            handlers=[\n",
    "                logging.FileHandler(self.log_dir / \"system.log\"),\n",
    "                logging.StreamHandler()\n",
    "            ]\n",
    "        )\n",
    "        self.logger = logging.getLogger(\"LogisticGuardian\")\n",
    "\n",
    "    def train_pipeline(self):\n",
    "        self.logger.info(\"--- Starting Training Pipeline ---\")\n",
    "\n",
    "        # 1. Load and Validate\n",
    "        df = pd.read_csv(self.data_path)\n",
    "        missing = [c for c in self.numeric_features + self.categorical_features if c not in df.columns]\n",
    "        if missing: raise ValueError(f\"Missing columns: {missing}\")\n",
    "\n",
    "        X = df[self.numeric_features + self.categorical_features]\n",
    "        y = df[self.target]\n",
    "\n",
    "        # 2. Split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, stratify=y, random_state=42\n",
    "        )\n",
    "\n",
    "        # 3. Build Transformers\n",
    "        preprocessor = ColumnTransformer([\n",
    "            (\"num\", StandardScaler(), self.numeric_features),\n",
    "            (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), self.categorical_features)\n",
    "        ])\n",
    "\n",
    "        # 4. Ensemble Model\n",
    "        ensemble = VotingClassifier(\n",
    "            estimators=[\n",
    "                (\"rf\", RandomForestClassifier(n_estimators=150, n_jobs=-1, random_state=42)),\n",
    "                (\"gb\", GradientBoostingClassifier(n_estimators=100, random_state=42))\n",
    "            ],\n",
    "            voting=\"soft\"\n",
    "        )\n",
    "\n",
    "        # 5. Full Pipeline with SMOTE\n",
    "        self.pipeline = Pipeline([\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            (\"smote\", SMOTE(random_state=42)),\n",
    "            (\"classifier\", ensemble)\n",
    "        ])\n",
    "\n",
    "        # 6. Fit & Evaluate\n",
    "        self.pipeline.fit(X_train, y_train)\n",
    "        self._generate_reports(X_test, y_test)\n",
    "\n",
    "        # 7. Save\n",
    "        joblib.dump(self.pipeline, self.model_filename)\n",
    "        self.logger.info(f\"Model successfully saved to {self.model_filename}\")\n",
    "\n",
    "    def _generate_reports(self, X_test, y_test):\n",
    "        y_pred = self.pipeline.predict(X_test)\n",
    "        y_proba = self.pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        # Save Metrics to Log\n",
    "        self.logger.info(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "        self.logger.info(f\"ROC-AUC: {roc_auc_score(y_test, y_proba):.4f}\")\n",
    "\n",
    "        # Visual 1: Confusion Matrix\n",
    "        plt.figure(figsize=(6, 5))\n",
    "        sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        plt.savefig(self.viz_dir / \"confusion_matrix.png\")\n",
    "\n",
    "        # Visual 2: Precision-Recall Curve (Crucial for logistics)\n",
    "        precision, recall, _ = precision_recall_curve(y_test, y_proba)\n",
    "        plt.figure(figsize=(6, 5))\n",
    "        plt.plot(recall, precision, color='darkorange', lw=2)\n",
    "        plt.xlabel('Recall')\n",
    "        plt.ylabel('Precision')\n",
    "        plt.title('Precision-Recall Curve')\n",
    "        plt.savefig(self.viz_dir / \"precision_recall.png\")\n",
    "        plt.close('all')\n",
    "\n",
    "    def predict_new(self, data: pd.DataFrame):\n",
    "        \"\"\"Method to predict on new, unseen data.\"\"\"\n",
    "        if self.pipeline is None:\n",
    "            self.pipeline = joblib.load(self.model_filename)\n",
    "\n",
    "        preds = self.pipeline.predict(data)\n",
    "        probs = self.pipeline.predict_proba(data)[:, 1]\n",
    "\n",
    "        data['predizione_ritardo'] = preds\n",
    "        data['probabilit√†_ritardo'] = np.round(probs, 3)\n",
    "        return data\n",
    "\n",
    "# --- Execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    guardian = LogisticGuardian(\"dataset_logistica_ml_10k.csv\")\n",
    "\n",
    "    # Run Training\n",
    "    guardian.train_pipeline()\n",
    "\n",
    "    # Simulation: Predict on a small sample of the same file\n",
    "    sample_data = pd.read_csv(\"dataset_logistica_ml_10k.csv\").head(5)\n",
    "    results = guardian.predict_new(sample_data.drop(columns=['ritardo']))\n",
    "    print(\"\\n--- Example Predictions ---\")\n",
    "    print(results[['distanza_km', 'modalit√†_trasporto', 'predizione_ritardo', 'probabilit√†_ritardo']])\n",
    "\n",
    "    ##\n"
   ],
   "id": "bef0ad7cc41a0f63",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-18 12:23:36,742 - INFO - --- Starting Training Pipeline ---\n",
      "2025-12-18 12:23:40,734 - INFO - Accuracy: 0.7730\n",
      "2025-12-18 12:23:40,740 - INFO - ROC-AUC: 0.5873\n",
      "2025-12-18 12:23:41,759 - INFO - Model successfully saved to models/logistic_guardian_v3_2.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Example Predictions ---\n",
      "   distanza_km modalit√†_trasporto  predizione_ritardo  probabilit√†_ritardo\n",
      "0          910             Strada                   1                0.698\n",
      "1         1344             Strada                   1                0.856\n",
      "2         1180             Strada                   1                0.791\n",
      "3         1145               Mare                   1                0.824\n",
      "4         1688           Ferrovia                   1                0.756\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T21:56:58.158941Z",
     "start_time": "2025-12-17T21:56:58.130723Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Example  below model also open terminal #cd D:\\Github_code_back\\esercizi-python-rajaroybca6\\logistic_project\n",
    "#streamlit run logistic_web.py"
   ],
   "id": "8b13c704eeb135e0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "' ' ' # üì¶ Example Shipment Scenarios\n",
    "\n",
    "## ‚úÖ SCENARIO 1: Perfect On-Time Delivery (0% Risk)\n",
    "\n",
    "### Input Values:\n",
    "- **Distance (km):** 150\n",
    "- **Cargo Value (‚Ç¨):** 5,000\n",
    "- **Weight (kg):** 200\n",
    "- **Number of Transits:** 0\n",
    "- **Weather Risk:** 1 (Clear conditions)\n",
    "- **Customs Risk:** 1 (Minimal complexity)\n",
    "- **Transport Mode:** Strada (Road)\n",
    "- **Fragile Goods:** No (0)\n",
    "- **GPS Tracking:** Active (1)\n",
    "\n",
    "### Why This is Low Risk:\n",
    "- ‚úÖ Short distance (local delivery)\n",
    "- ‚úÖ Low cargo value (minimal security concerns)\n",
    "- ‚úÖ Light weight (easy handling)\n",
    "- ‚úÖ No transit points (direct route)\n",
    "- ‚úÖ Perfect weather conditions\n",
    "- ‚úÖ Simple customs (domestic)\n",
    "- ‚úÖ GPS tracking enabled\n",
    "- ‚úÖ Non-fragile goods\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ö†Ô∏è SCENARIO 2: Medium Risk (40-60% Delay)\n",
    "\n",
    "### Input Values:\n",
    "- **Distance (km):** 800\n",
    "- **Cargo Value (‚Ç¨):** 25,000\n",
    "- **Weight (kg):** 800\n",
    "- **Number of Transits:** 3\n",
    "- **Weather Risk:** 3 (Moderate concerns)\n",
    "- **Customs Risk:** 3 (Some complexity)\n",
    "- **Transport Mode:** Strada (Road)\n",
    "- **Fragile Goods:** Yes (1)\n",
    "- **GPS Tracking:** Active (1)\n",
    "\n",
    "### Why This is Medium Risk:\n",
    "- ‚ö†Ô∏è Medium distance (regional)\n",
    "- ‚ö†Ô∏è Moderate cargo value\n",
    "- ‚ö†Ô∏è Multiple transit points\n",
    "- ‚ö†Ô∏è Weather could cause delays\n",
    "- ‚ö†Ô∏è Fragile goods need careful handling\n",
    "- ‚úÖ GPS tracking helps monitoring\n",
    "\n",
    "---\n",
    "\n",
    "## üö® SCENARIO 3: High Risk - Delay Predicted (80-95% Risk)\n",
    "\n",
    "### Input Values:\n",
    "- **Distance (km):** 3,500\n",
    "- **Cargo Value (‚Ç¨):** 150,000\n",
    "- **Weight (kg):** 2,500\n",
    "- **Number of Transits:** 8\n",
    "- **Weather Risk:** 5 (Severe conditions - storms/snow)\n",
    "- **Customs Risk:** 5 (Complex international shipping)\n",
    "- **Transport Mode:** Mare (Sea) or Strada (Road)\n",
    "- **Fragile Goods:** Yes (1)\n",
    "- **GPS Tracking:** Not Active (0)\n",
    "\n",
    "### Why This is High Risk:\n",
    "- üî¥ Very long distance (international)\n",
    "- üî¥ High value cargo (theft/insurance concerns)\n",
    "- üî¥ Heavy weight (handling challenges)\n",
    "- üî¥ Multiple transit points (8 handoffs)\n",
    "- üî¥ Severe weather conditions\n",
    "- üî¥ Complex customs procedures\n",
    "- üî¥ Fragile goods with no GPS tracking\n",
    "- üî¥ No real-time monitoring\n",
    "\n",
    "---\n",
    "\n",
    "## üåä SCENARIO 4: Extreme Risk - Almost Certain Delay (95%+ Risk)\n",
    "\n",
    "### Input Values:\n",
    "- **Distance (km):** 5,000\n",
    "- **Cargo Value (‚Ç¨):** 250,000\n",
    "- **Weight (kg):** 5,000\n",
    "- **Number of Transits:** 10\n",
    "- **Weather Risk:** 5 (Hurricane/Typhoon season)\n",
    "- **Customs Risk:** 5 (Multiple countries, complex regulations)\n",
    "- **Transport Mode:** Mare (Sea)\n",
    "- **Fragile Goods:** Yes (1)\n",
    "- **GPS Tracking:** Not Active (0)\n",
    "\n",
    "### Why This is Extreme Risk:\n",
    "- üî¥ Intercontinental distance\n",
    "- üî¥ Very high value (requires special security)\n",
    "- üî¥ Very heavy cargo\n",
    "- üî¥ Maximum transit complexity\n",
    "- üî¥ Extreme weather threats\n",
    "- üî¥ Multiple international borders\n",
    "- üî¥ Sea transport (longer, more variables)\n",
    "- üî¥ No tracking capability\n",
    "- üî¥ Fragile goods at high risk\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ SCENARIO 5: Express Air - Low Risk Despite Distance\n",
    "\n",
    "### Input Values:\n",
    "- **Distance (km):** 2,000\n",
    "- **Cargo Value (‚Ç¨):** 30,000\n",
    "- **Weight (kg):** 150\n",
    "- **Number of Transits:** 1\n",
    "- **Weather Risk:** 2 (Minor concerns)\n",
    "- **Customs Risk:** 2 (Pre-cleared)\n",
    "- **Transport Mode:** Aereo (Air)\n",
    "- **Fragile Goods:** No (0)\n",
    "- **GPS Tracking:** Active (1)\n",
    "\n",
    "### Why This is Still Low Risk:\n",
    "- ‚úÖ Air transport (fastest mode)\n",
    "- ‚úÖ Single transit point (airport to airport)\n",
    "- ‚úÖ Light weight (priority handling)\n",
    "- ‚úÖ GPS tracking throughout\n",
    "- ‚úÖ Pre-cleared customs\n",
    "- ‚úÖ Non-fragile goods\n",
    "- ‚ö†Ô∏è Distance offset by speed\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Quick Reference Table\n",
    "\n",
    "| Scenario | Distance | Value | Transits | Weather | Customs | GPS | Expected Risk |\n",
    "|----------|----------|-------|----------|---------|---------|-----|---------------|\n",
    "| Perfect  | 150 km   | ‚Ç¨5K   | 0        | 1       | 1       | ‚úÖ  | 0-10%        |\n",
    "| Medium   | 800 km   | ‚Ç¨25K  | 3        | 3       | 3       | ‚úÖ  | 40-60%       |\n",
    "| High     | 3,500 km | ‚Ç¨150K | 8        | 5       | 5       | ‚ùå  | 80-95%       |\n",
    "| Extreme  | 5,000 km | ‚Ç¨250K | 10       | 5       | 5       | ‚ùå  | 95%+         |\n",
    "| Express  | 2,000 km | ‚Ç¨30K  | 1        | 2       | 2       | ‚úÖ  | 10-20%       |\n",
    "\n",
    "---\n",
    "\n",
    "## üí° Tips for Testing\n",
    "\n",
    "1. **Start with Perfect scenario** - Should show green \"ON TIME\"\n",
    "2. **Gradually increase risk factors** - Watch probability climb\n",
    "3. **Test extreme scenario** - Should show red \"DELAY PREDICTED\"\n",
    "4. **Mix factors** - See how different combinations affect risk\n",
    "5. **Try transport modes** - Air typically lowest risk for long distance\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Key Insights\n",
    "\n",
    "**Risk Multipliers:**\n",
    "- Each transit point adds complexity\n",
    "- Weather risk ‚â• 4 significantly increases delays\n",
    "- No GPS tracking removes visibility and control\n",
    "- Fragile goods require extra handling time\n",
    "- High value cargo needs additional security checks\n",
    "- Sea transport has more variables than air/road\n",
    "\n",
    "**Risk Reducers:**\n",
    "- GPS tracking provides proactive management\n",
    "- Fewer transit points = fewer failure points\n",
    "- Good weather = predictable timeline\n",
    "- Simple customs = faster processing\n",
    "- Non-fragile goods = standard handling\n",
    "- Moderate distances = fewer complications\n",
    "' ' '"
   ],
   "id": "b361925e1e8e71da"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T11:23:02.060385Z",
     "start_time": "2025-12-18T11:22:56.514075Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import logging\n",
    "import warnings\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# ML & Preprocessing\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, accuracy_score,\n",
    "    f1_score, roc_auc_score, roc_curve, precision_recall_curve\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Note: Requires 'pip install imbalanced-learn shap'\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import shap\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "class LogisticGuardian:\n",
    "    \"\"\"\n",
    "    Unified System for Training and Predicting Logistics Delays.\n",
    "    \"\"\"\n",
    "    def __init__(self, data_path: str = \"dataset_logistica_ml_10k.csv\"):\n",
    "        self.data_path = data_path\n",
    "        self.model_filename = \"models/logistic_guardian_v3_2.pkl\"\n",
    "        self.viz_dir = Path(\"visualizations\")\n",
    "        self.log_dir = Path(\"logs\")\n",
    "\n",
    "        # Setup folders\n",
    "        for folder in [self.viz_dir, self.log_dir, Path(\"models\")]:\n",
    "            folder.mkdir(exist_ok=True)\n",
    "\n",
    "        self._setup_logging()\n",
    "        self.pipeline = None\n",
    "\n",
    "        # Schema definition\n",
    "        self.numeric_features = [\n",
    "            \"distanza_km\", \"valore_merce_eur\", \"peso_kg\",\n",
    "            \"numero_transiti\", \"rischio_meteo\", \"rischio_doganale\"\n",
    "        ]\n",
    "        self.categorical_features = [\"modalit√†_trasporto\", \"fragile\", \"tracking_gps\"]\n",
    "        self.target = \"ritardo\"\n",
    "\n",
    "    def _setup_logging(self):\n",
    "        logging.basicConfig(\n",
    "            level=logging.INFO,\n",
    "            format=\"%(asctime)s [%(levelname)s] %(message)s\",\n",
    "            handlers=[\n",
    "                logging.FileHandler(self.log_dir / \"system.log\"),\n",
    "                logging.StreamHandler()\n",
    "            ]\n",
    "        )\n",
    "        self.logger = logging.getLogger(\"LogisticGuardian\")\n",
    "\n",
    "    def train_pipeline(self):\n",
    "        self.logger.info(\"--- Starting Training Pipeline ---\")\n",
    "\n",
    "        # 1. Load and Validate\n",
    "        df = pd.read_csv(self.data_path)\n",
    "        missing = [c for c in self.numeric_features + self.categorical_features if c not in df.columns]\n",
    "        if missing: raise ValueError(f\"Missing columns: {missing}\")\n",
    "\n",
    "        X = df[self.numeric_features + self.categorical_features]\n",
    "        y = df[self.target]\n",
    "\n",
    "        # 2. Split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, stratify=y, random_state=42\n",
    "        )\n",
    "\n",
    "        # 3. Build Transformers\n",
    "        preprocessor = ColumnTransformer([\n",
    "            (\"num\", StandardScaler(), self.numeric_features),\n",
    "            (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), self.categorical_features)\n",
    "        ])\n",
    "\n",
    "        # 4. Ensemble Model\n",
    "        ensemble = VotingClassifier(\n",
    "            estimators=[\n",
    "                (\"rf\", RandomForestClassifier(n_estimators=150, n_jobs=-1, random_state=42)),\n",
    "                (\"gb\", GradientBoostingClassifier(n_estimators=100, random_state=42))\n",
    "            ],\n",
    "            voting=\"soft\"\n",
    "        )\n",
    "\n",
    "        # 5. Full Pipeline with SMOTE\n",
    "        self.pipeline = Pipeline([\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            (\"smote\", SMOTE(random_state=42)),\n",
    "            (\"classifier\", ensemble)\n",
    "        ])\n",
    "\n",
    "        # 6. Fit & Evaluate\n",
    "        self.pipeline.fit(X_train, y_train)\n",
    "        self._generate_reports(X_test, y_test)\n",
    "\n",
    "        # 7. Save\n",
    "        joblib.dump(self.pipeline, self.model_filename)\n",
    "        self.logger.info(f\"Model successfully saved to {self.model_filename}\")\n",
    "\n",
    "    def _generate_reports(self, X_test, y_test):\n",
    "        y_pred = self.pipeline.predict(X_test)\n",
    "        y_proba = self.pipeline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        # Save Metrics to Log\n",
    "        self.logger.info(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "        self.logger.info(f\"ROC-AUC: {roc_auc_score(y_test, y_proba):.4f}\")\n",
    "\n",
    "        # Visual 1: Confusion Matrix\n",
    "        plt.figure(figsize=(6, 5))\n",
    "        sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        plt.savefig(self.viz_dir / \"confusion_matrix.png\")\n",
    "\n",
    "        # Visual 2: Precision-Recall Curve (Crucial for logistics)\n",
    "        precision, recall, _ = precision_recall_curve(y_test, y_proba)\n",
    "        plt.figure(figsize=(6, 5))\n",
    "        plt.plot(recall, precision, color='darkorange', lw=2)\n",
    "        plt.xlabel('Recall')\n",
    "        plt.ylabel('Precision')\n",
    "        plt.title('Precision-Recall Curve')\n",
    "        plt.savefig(self.viz_dir / \"precision_recall.png\")\n",
    "        plt.close('all')\n",
    "\n",
    "    def predict_new(self, data: pd.DataFrame):\n",
    "        \"\"\"Method to predict on new, unseen data.\"\"\"\n",
    "        if self.pipeline is None:\n",
    "            self.pipeline = joblib.load(self.model_filename)\n",
    "\n",
    "        preds = self.pipeline.predict(data)\n",
    "        probs = self.pipeline.predict_proba(data)[:, 1]\n",
    "\n",
    "        data['predizione_ritardo'] = preds\n",
    "        data['probabilit√†_ritardo'] = np.round(probs, 3)\n",
    "        return data\n",
    "\n",
    "# --- Execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    guardian = LogisticGuardian(\"dataset_logistica_ml_10k.csv\")\n",
    "\n",
    "    # Run Training\n",
    "    guardian.train_pipeline()\n",
    "\n",
    "    # Simulation: Predict on a small sample of the same file\n",
    "    sample_data = pd.read_csv(\"dataset_logistica_ml_10k.csv\").head(5)\n",
    "    results = guardian.predict_new(sample_data.drop(columns=['ritardo']))\n",
    "    print(\"\\n--- Example Predictions ---\")\n",
    "    print(results[['distanza_km', 'modalit√†_trasporto', 'predizione_ritardo', 'probabilit√†_ritardo']])"
   ],
   "id": "308fba6bf0ca1bd8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-18 12:22:56,838 - INFO - --- Starting Training Pipeline ---\n",
      "2025-12-18 12:23:01,111 - INFO - Accuracy: 0.7730\n",
      "2025-12-18 12:23:01,115 - INFO - ROC-AUC: 0.5873\n",
      "2025-12-18 12:23:01,872 - INFO - Model successfully saved to models/logistic_guardian_v3_2.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Example Predictions ---\n",
      "   distanza_km modalit√†_trasporto  predizione_ritardo  probabilit√†_ritardo\n",
      "0          910             Strada                   1                0.698\n",
      "1         1344             Strada                   1                0.856\n",
      "2         1180             Strada                   1                0.791\n",
      "3         1145               Mare                   1                0.824\n",
      "4         1688           Ferrovia                   1                0.756\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "42a1c98d8a49150f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-18T11:29:32.973381Z",
     "start_time": "2025-12-18T11:29:32.635262Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Use quotes around the path.\n",
    "# 2. Add 'r' before the path to handle the backslashes (\\) correctly in Windows.\n",
    "path = r\"D:\\Github_code_back\\esercizi-python-rajaroybca6\\logistic_project\\dataset_logistica_ml_10k.csv\"\n",
    "\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "# To see the column names (headers)\n",
    "print(df.columns)\n",
    "\n",
    "# To see the first 5 rows of data\n",
    "print(df.head())"
   ],
   "id": "3fb085a9342e4064",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['distanza_km', 'valore_merce_eur', 'peso_kg', 'fragile',\n",
      "       'numero_transiti', 'rischio_meteo', 'rischio_doganale', 'tracking_gps',\n",
      "       'modalit√†_trasporto', 'ritardo'],\n",
      "      dtype='object')\n",
      "   distanza_km  valore_merce_eur  peso_kg  fragile  numero_transiti  \\\n",
      "0          910            131842      366        1                2   \n",
      "1         1344            265418     7835        0                1   \n",
      "2         1180            151033      655        0                0   \n",
      "3         1145             21044      624        0                2   \n",
      "4         1688            100372     1227        0                2   \n",
      "\n",
      "   rischio_meteo  rischio_doganale  tracking_gps modalit√†_trasporto  ritardo  \n",
      "0              2                 5             1             Strada        1  \n",
      "1              5                 1             0             Strada        1  \n",
      "2              4                 3             0             Strada        1  \n",
      "3              4                 5             0               Mare        1  \n",
      "4              2                 1             0           Ferrovia        1  \n"
     ]
    }
   ],
   "execution_count": 22
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
